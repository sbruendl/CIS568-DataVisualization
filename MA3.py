# -*- coding: utf-8 -*-
"""NetwordX_JSON.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OcnlgVMj3WVSzikTNhNs-tad5QwXMjAG
"""

#Title 
#Year  
#EID 
#Abstract  
#Publisher 
#Conference name 
#Conference date 
#Authors 
#Author(s) ID  
#Authors with affiliations 
#Source title  
#Abbreviated Source Title  
#Cited by   MAX: 277

import pandas as pd
import networkx as nx
import json
pd.set_option('display.max_columns', None)
import matplotlib.pyplot as plt
import pprint

df = pd.read_csv("https://raw.githubusercontent.com/umassdgithub/Week-8-part-1/main/data/data_scopus.csv")
## drop the rows with no Author Affiliations
#also drop the rows with no year/author

df= df[~pd.isnull(df['Authors with affiliations'])].copy()
df= df[~pd.isnull(df['Year'])].copy()
df= df[~pd.isnull(df['Authors'])].copy()
df= df[~pd.isnull(df['Author(s) ID'])].copy()

df.head(2)

def get_first_author_affilation(x):
  try:
    return x.split(";")[0].split(",")[-1].strip()
  except Exception as ex:
    print(x)
df['First_author_Country']=df['Authors with affiliations'].apply(get_first_author_affilation)

df['First_author_Country']

df.Year.hist()

df["Source title"].value_counts().reset_index()

nodes = df['Title'].value_counts#replace EID with Title
df = df.fillna(0)

df['Year'].max()

G = nx.Graph()

nodes = []

for row in df.iterrows():
  nodes.append((row[1]['Title'],{
      "Publisher": row[1]['Publisher'],
      "Year" : row[1]['Year'],
      "Citations" : row[1]['Cited by'],
      "Country" : row[1]['First_author_Country'],
      "EID" : row[1]['EID'],
  }
  ))

len(nodes)

nodes[0]

G.add_nodes_from(nodes)

#in the df, separate every row's authors and store them in "authors"
# for every stored aithor, store all papers (using UNIQUE EID) they appear in in the df
#  create an edge for every paper that meets these criteria except self

#that means I don't have to modify anything here. This already links based on co-authors

edges = []
for row in df.iterrows():
  current_paper = row[1]['EID']
  if ";" in row[1]['Author(s) ID']: 
    authors = row[1]['Author(s) ID'][:-1].split(";")
    for author in authors:
      papers = df[df['Author(s) ID'].str.contains(author)]['EID'].values
      if len(papers)>0:
        for paper in papers:
          if paper != current_paper:
            edges.append((current_paper,paper))
  else:
    continue



G.add_edges_from(edges)

#pos = nx.drawing.circular_layout(G)
pos = nx.spring_layout(G)

nx.draw(G,pos=pos, node_size=40,alpha=.2)

from networkx.readwrite import json_graph

with open("publication_network_MA3.json",'w') as f:
  json.dump(json_graph.node_link_data(G),f)

nx.write_gml(G,"network_MA3.gml")

